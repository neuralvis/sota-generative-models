# 01.3 Consistency and Statefulness


## Models for Statefulness and consistency across inference

1. **CUT3R** (also Renderformer, VGGT)
2. **Markovian Thinker**
3. Tiny Reasoning model
4. **Mamba 3** - like model
5. [RTFM](https://www.worldlabs.ai/blog/rtfm)

We are strong believers in The Bitter Lesson: simple methods that scale gracefully with increasing compute tend to dominate in AI, since they can benefit from the exponentially decreasing costs of compute that have driven all of technology forward for decades. Generative World Models are perfectly positioned to benefit from a future where the cost of computation continues to fall.


- https://jen-pan.github.io/memer/
- **Kinaema**: A recurrent sequence model for memory and pose in motion: http://arxiv.org/abs/2510.20261
	- https://x.com/chriswolfvision/status/1981630434338312461 
- [The free transformer by Meta](https://arxiv.org/abs/2510.17558v1)
- **[Recurrence Complete Frame based Action Models](https://arxiv.org/abs/2510.06828)** - Prime Intellect Paper
- DeepSeek OCR



## Continual Learning

1. [The Continual Learning Problem](https://jessylin.com/2025/10/20/continual-learning/)