# Optimizations

## Introductory Material
- https://hanlab.mit.edu/courses/2024-fall-65940
	- https://hanlab.mit.edu/projects/tinyml
- Meta Paper on Quantization Strategies for Diffusion Models

- [A visual guide to quantization](https://substack.com/inbox/post/145531349)


## StableDiffusion.cpp

Code: https://github.com/leejet/stable-diffusion.cpp

- [Overview of GGUF based quantization approaches](https://www.reddit.com/r/LocalLLaMA/comments/1ba55rj/overview_of_gguf_quantization_methods/)
- [Details on Flux LORA Quantization with Diffusers](https://github.com/huggingface/diffusers/tree/main/examples/research_projects/flux_lora_quantization)


## GPTQ and GGUF
- [Overview of quantization approaches](https://substack.com/inbox/post/145531349)


## Attention optimizations

- [Understanding Paged Attention](https://hamzaelshafie.bearblog.dev/paged-attention-from-first-principles-a-view-inside-vllm/)

- [DeltaNet Explained](https://sustcsonglin.github.io/blog/2024/deltanet-1/)

## VAE Optimizations

- https://huggingface.co/lightx2v/Autoencoders


## Tools
- [OneDiff](https://github.com/siliconflow/onediff)
- [Nexa AI](https://github.com/NexaAI/nexa-sdk)
- [XDiT](https://github.com/xdit-project/xDiT)



