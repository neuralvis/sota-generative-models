# 01.1 SoTA Open Models

## Autoregressive Video Models

2. **[SkyReels-V2](https://github.com/SkyworkAI/SkyReels-V2)** - Open-source video model that uses diffusion forcing to generate continuous videos.
3. **[CausVid](https://causvid.github.io/#result)**
7. **[Self-Forcing](https://self-forcing.github.io)**
8. **[Matrix-Game 2.0](https://matrix-game-v2.github.io)**
9. **[Hunyuan Gamecraft](https://hunyuan-gamecraft.github.io)**
10. **[Tencentâ€™s Interactive Video Generation](https://greatx3.github.io/Yan/)**


## UMMs
- [Emu3](https://github.com/baaivision/Emu3?tab=readme-ov-file)
- **[Show-O](https://github.com/showlab/Show-o)**
- [Chameleon](https://arxiv.org/abs/2405.09818)
	- https://unfoldai.com/meta-chameleon/
- **[MMaDA](https://github.com/Gen-Verse/MMaDA?tab=readme-ov-file)**
- [MS Phi-3 Vision Instruct](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct)
- **[LaViDa](https://homepage.jackli.org/projects/lavida/)** - Controllable Multimodal generation.
- [NEO - Natively Trained VLMs](https://github.com/EvolvingLMMs-Lab/NEO)
- [OneFlow - Interleaved Generation using Diffusion](https://oneflow.framer.ai/)


## Open Video Models

2. [Mochi1 preview](https://huggingface.co/genmo/mochi-1-preview)
3. [CogVideoX-5b](https://huggingface.co/THUDM/CogVideoX-5b)
4. [Hunyuan Video](https://huggingface.co/tencent/HunyuanVideo)
5. [OpenSora v2](https://huggingface.co/hpcai-tech/Open-Sora-v2)
6. **[WAN 2.1 - Apache Licensed](https://github.com/Wan-Video/Wan2.1)**
2. **[WAN 2.2 - Apache Licensed](https://github.com/Wan-Video/Wan2.1)**


## Robotics Focus
1. [FlowVLA](https://irpn-lab.github.io/FlowVLA/)
2. [MOLMO Act](https://allenai.org/blog/molmoact) - reasoning in 3D Space


## LLM and Multimodal
1. [MiniMax-M2](https://github.com/MiniMax-AI/MiniMax-M2)
2. Kimi-K2
3. Qwen3-VL

## Startups

1. https://enigma-labs.io/blog
2. https://github.com/EnigmaLabsAI/multiverse
3. Odyssey.world