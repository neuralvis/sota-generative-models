# Understanding Autoencoders

https://www.jeremyjordan.me/variational-autoencoders/

https://medium.com/@weidagang/demystifying-neural-networks-variational-autoencoders-6a44e75d0271

**https://medium.com/data-science/understanding-variational-autoencoders-vaes-f70510919f73**

https://medium.com/@rushikesh.shende/autoencoders-variational-autoencoders-vae-and-β-vae-ceba9998773d

https://www.youtube.com/@Deepia-ls2fo

https://www.tilderesearch.com/blog/rate-distortion-saes

## Random but useful VAE Nuggets
- Some intuitions about the VAE Encoders are articulated [here](https://x.com/sang_yun_lee/status/1912548035717931304) and reference the following works
	- [Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models](https://arxiv.org/abs/2410.10733)
	- [Diagnosing and Enhancing VAE models](https://arxiv.org/abs/1903.05789)
- Series of posts by Rudy Gilman on VAEs
	- *[The attention layers in the VAEs for FLUX, Stable Diffusion 3.5, and SDXL don't do anything.](https://x.com/rgilman33/status/1914273430611906590)*
	- [*Here's broadly how I think the SDXL-VAE escapes the "tyranny of the grid”.*](https://x.com/rgilman33/status/1912206589173571616)

## Good Technical Blogs

- [Generative Modeling in Latent Space by Sander Dielman](https://github.com/hustvl/LightningDiT) - Talks extensively about latents


## Tools

### Visualizing Latents
- **[DarkSpark](https://darkspark.dev)**
- https://github.com/jessevig/bertviz
- https://github.com/guoqincode/DiT-Visualization


- ComfyUI + Latent Visualization
	- https://colab.research.google.com/drive/1176r3ZVqqxzVoj1pfq068_ehnLYdWoxm#scrollTo=Q0V1MtewwhZo
	- https://x.com/prathyvsh/status/1852215239850225943

- https://github.com/mashaan14/VisionTransformer-MNIST/blob/main/VisionTransformer_MNIST.ipynb

- https://x.com/msfeldstein/status/1849518352059990428
	- Code: [Sliding in Latent Space](https://colab.research.google.com/drive/1176r3ZVqqxzVoj1pfq068_ehnLYdWoxm#scrollTo=Q0V1MtewwhZo)

### Hash Grid Encoding
- https://github.com/Ending2015a/hash-grid-encoding
- https://sair.synerise.com/emde-vs-multiresolution-hash-encoding/
- https://sair.synerise.com/emde-illustrated/

### Disentangling Latents
Sliderspace - https://sliderspace.baulab.info


## Anthropic Research on Interpretability
- https://www.anthropic.com/research#interpretability
- https://transformer-circuits.pub